# üìä Probability Notes (with Python Examples)

This folder contains **step-by-step notes with Python examples** to learn Probability for **Machine Learning and Data Science**.  
Each file is written in simple Python comment style and explains the concept clearly with examples.

---

## üìö Topics Covered

### 1. Terminology of Probability
- Basic terms used in probability such as experiment, sample space, event, and outcome.  
- Foundation for all other probability concepts.

### 2. Types of Events in Probability
- Mutually exclusive events, independent events, complementary events, and more.  
- Helps in classifying scenarios in probability.

### 3. What is Probability?
- Introduction to the definition and formula of probability.  
- Explains probability as "favorable outcomes / total outcomes".

### 4. Types of Probability
- Theoretical, experimental, subjective, and axiomatic probability.  
- Understanding different approaches to probability.

### 5. Random Variable in Probability
- What is a random variable (discrete and continuous)?  
- How variables take values based on outcomes.

### 6. Probability Distribution of a Random Variable
- Explains distribution of values a random variable can take.  
- Foundation for discrete and continuous distributions.

### 7. Mean of Random Variable
- Expected value (mean) of a random variable.  
- Why expectation is important in statistics and ML.

### 8. Variance of Random Variable
- Variability/spread of a random variable.  
- Used in model evaluation and statistical analysis.

### 9. Venn Diagram in Probability
- Graphical representation of probability events.  
- Shows union, intersection, and complements.

### 10. Contingency Table in Probability
- Tabular representation of categorical data.  
- Helps calculate joint, marginal, and conditional probabilities.

### 11. Joint Probability
- Probability of two or more events happening together.  
- Example: P(A ‚à© B).

### 12. Marginal Probability
- Probability of a single event occurring regardless of others.  
- Derived from joint probability.

### 13. Conditional Probability
- Probability of one event given that another event has already occurred.  
- Formula: P(A|B) = P(A ‚à© B) / P(B).

### 14. Independent vs Mutually Exclusive Events
- Difference between independence and mutual exclusivity.  
- Crucial for probability in ML algorithms.

### 15. Bayes Theorem
- Fundamental rule to update probability when new evidence is introduced.  
- Core of Bayesian learning and Naive Bayes classifier.

### 16. Discrete Probability Distributions
- Probability distributions where random variables take discrete values.  
- Example: Binomial, Poisson distributions.

### 17. Continuous Probability Distributions
- Probability distributions where variables take continuous values.  
- Example: Normal, Exponential distributions.

### 18. Sampling Distributions
- Distribution of sample statistics (like sample mean).  
- Foundation for inferential statistics.

### 19. Central Limit Theorem
- Key theorem: Sampling distribution of the mean tends to normal distribution as sample size increases.  
- Basis for hypothesis testing and many ML assumptions.

---

## üèÜ Why Learn Probability?
- Probability is the **backbone of statistics and ML**.  
- Concepts like **Bayes Theorem, Distributions, and CLT** directly power ML algorithms.  
- Helps in understanding uncertainty, randomness, and decision-making in AI systems.

---

